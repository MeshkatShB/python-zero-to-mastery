{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Software Testing\n",
    "In this notebook, we examine how we can test our application/program in Python. As you may know, we have two different types of software testing in general: `Manual` or `Automated`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Types of Software Testing\n",
    "Every test can be done in either `manual` or `automated` way. For more understanding, see below:\n",
    "### Manual Testing\n",
    "   - Test Case Development\n",
    "      - Types of test cases: Positive, Negative, Boundary.\n",
    "   - Test Execution\n",
    "        - Executing test cases manually.\n",
    "        - Recording results and logging defects.\n",
    "   - **Tools**: JIRA, Bugzilla, TestRail\n",
    "### Automated Testing\n",
    "- Consider when to automate and when not to automate.\n",
    "- **Tools**: Selenium, JUnit, TestNG, PyTest\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functional vs. Non-Functional\n",
    "Each test case, can be written either `functional` or `non-functional`.\n",
    "\n",
    "### Definition\n",
    "**Functional Testing**:\n",
    "- Focuses on verifying that the software `functions correctly` according to the requirements.\n",
    "- Tests `individual features` and `functions` of the software.\n",
    "- Includes types like `unit testing`, `integration testing`, `system testing`, and `acceptance testing`.\n",
    "\n",
    "**Non-Functional Testing**:\n",
    "- Focuses on verifying `non-functional aspects` of the software, such as `performance`, `usability`, `reliability`, etc.\n",
    "- Ensures the software meets `certain criteria not related to specific behaviors or functions`.\n",
    "- Includes types like `performance testing`, `load testing`, `security testing`, and `usability testing`.\n",
    "\n",
    "### 1. Functional Testing\n",
    "#### 1.1. Unit Testing\n",
    "- Definition: Testing individual components or modules of the software in isolation.\n",
    "- Purpose: To ensure that each unit of the software performs as expected.\n",
    "- Example: Testing a single function in a codebase to ensure it returns the correct result.\n",
    "\n",
    "#### 1.2. Integration Testing\n",
    "- Definition: Testing the interaction between integrated units/modules.\n",
    "- Purpose: To identify issues in the interaction between different units.\n",
    "- Example: Testing the data flow between a login module and a user profile module.\n",
    "#### 1.3. System Testing\n",
    "- Definition: Testing the complete and integrated software system.\n",
    "- Purpose: To verify the system’s compliance with specified requirements.\n",
    "- Example: Testing the entire application’s workflow from start to finish.\n",
    "#### 1.4. Acceptance Testing\n",
    "- Definition: Testing conducted to determine if the system satisfies the acceptance criteria.\n",
    "- Purpose: To ensure the system meets business requirements and is ready for deployment.\n",
    "- Example: A user acceptance test (UAT) where end-users validate the functionality.\n",
    "### 2. Non-Functional Testing\n",
    "#### 2.1. Performance Testing\n",
    "- Definition: Testing to determine the performance of the software under specific conditions.\n",
    "- Purpose: To ensure the software meets performance requirements.\n",
    "- Example: Measuring the response time of a web application under a certain load.\n",
    "#### 2.2. Load Testing\n",
    "- Definition: Testing to determine how the system behaves under an expected load.\n",
    "- Purpose: To identify performance bottlenecks and ensure the system can handle expected traffic.\n",
    "- Example: Simulating thousands of users accessing a website simultaneously.\n",
    "#### 2.3. Security Testing\n",
    "- Definition: Testing to determine how the system behaves under extreme conditions.\n",
    "- Purpose: To identify the system’s breaking point and how it recovers from failures.\n",
    "- Example: Increasing the load on a server until it crashes to test its resilience.\n",
    "#### 2.4. Usability Testing\n",
    "- Definition: Testing to identify vulnerabilities and ensure the system is protected against threats.\n",
    "- Purpose: To ensure data integrity, confidentiality, and security.\n",
    "- Example: Performing penetration testing to find security weaknesses."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Understanding the Difference [functinoal/non-functional vs. manual/automated]\n",
    "Here is a comprehensive table about the relation between functinoal/non-functional testing and manual/automated testing:\n",
    "\n",
    "\n",
    "| Testing Type            | Manual Testing                           | Automated Testing                           |\n",
    "|-------------------------|------------------------------------------|---------------------------------------------|\n",
    "| **Functional Testing**  | Manually executing test cases to verify functionality (e.g., logging in, form submission). | Automating test cases to verify functionality using tools like Selenium, JUnit, or PyTest. |\n",
    "| **Non-Functional Testing** | Manually assessing usability, and user experience, which require human interaction. | Automating performance, load, and security tests using tools like JMeter, LoadRunner, or automated scripts. |\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Code\n",
    "First, we need to install `pytest` package following the command below:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-07-10T11:59:42.488954Z",
     "end_time": "2024-07-10T11:59:52.592413Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytest\n",
      "  Downloading pytest-8.2.2-py3-none-any.whl (339 kB)\n",
      "     ------------------------------------ 339.9/339.9 kB 439.5 kB/s eta 0:00:00\n",
      "Collecting iniconfig\n",
      "  Using cached iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Requirement already satisfied: tomli>=1 in h:\\documents\\work\\python-zero-to-mastery\\venv\\lib\\site-packages (from pytest) (2.0.1)\n",
      "Requirement already satisfied: colorama in h:\\documents\\work\\python-zero-to-mastery\\venv\\lib\\site-packages (from pytest) (0.4.6)\n",
      "Requirement already satisfied: packaging in h:\\documents\\work\\python-zero-to-mastery\\venv\\lib\\site-packages (from pytest) (24.1)\n",
      "Collecting pluggy<2.0,>=1.5\n",
      "  Using cached pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in h:\\documents\\work\\python-zero-to-mastery\\venv\\lib\\site-packages (from pytest) (1.2.1)\n",
      "Installing collected packages: pluggy, iniconfig, pytest\n",
      "Successfully installed iniconfig-2.0.0 pluggy-1.5.0 pytest-8.2.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Our Application\n",
    "For example, we have an application (in this case, a function) which gets two numbers: `a` and `b` and returns the sum of them."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def add(a: int, b: int) -> int:\n",
    "    return a + b\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-10T12:00:59.345613Z",
     "end_time": "2024-07-10T12:00:59.368151Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Write a Test Case\n",
    "We have 3 samples. We just Assert that if the input of our function are for example `2` and `3`, we should get `5`. With this method, we `assert` that we get the designated result (the result that we expect)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def test_add():\n",
    "    assert add(2, 3) == 5\n",
    "    assert add(-1, 1) == 0\n",
    "    assert add(-1, -1) == -2\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-10T12:02:10.645551Z",
     "end_time": "2024-07-10T12:02:10.674542Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "test_add()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-10T12:03:52.675398Z",
     "end_time": "2024-07-10T12:03:52.693400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Analysis\n",
    "As you can see, we didn't get any errors from calling above function. In example below, you can see that we get errors if our function is not working properly:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def add2(a: int, b: int) -> int:\n",
    "    return a + b + 1        # should not have 1. for demonstrating error purposes\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-10T12:05:53.593706Z",
     "end_time": "2024-07-10T12:05:53.638719Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 6\u001B[0m\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m add2(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m add2(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m\n\u001B[1;32m----> 6\u001B[0m \u001B[43mtest_add2\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[15], line 2\u001B[0m, in \u001B[0;36mtest_add2\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtest_add2\u001B[39m():\n\u001B[1;32m----> 2\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m add2(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m5\u001B[39m\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m add2(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m add2(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m\n",
      "\u001B[1;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def test_add2():\n",
    "    assert add2(2, 3) == 5\n",
    "    assert add2(-1, 1) == 0\n",
    "    assert add2(-1, -1) == -2\n",
    "\n",
    "test_add2()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-10T12:06:11.277158Z",
     "end_time": "2024-07-10T12:06:11.292919Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
